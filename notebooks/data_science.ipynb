{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gitignore"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".vscode\n",
    ".DS_Store\n",
    "*.pbix\n",
    "*.gitignore\n",
    "cache/\n",
    ".ini\n",
    "__pycache__\n",
    "env.py\n",
    ".env\n",
    "\n",
    "# Jupyter Notebook\n",
    ".ipynb_checkpoints\n",
    "\n",
    "# Environments\n",
    ".env\n",
    ".venv\n",
    "env/\n",
    "venv/\n",
    "ENV/\n",
    "env.bak/\n",
    "venv.bak/\n",
    "v312/\n",
    "\n",
    "# Data Folder\n",
    "data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using .env file with dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the random seed for reproducibility\n",
    "import random\n",
    "random.seed(493)\n",
    "\n",
    "# for manipulating dataframes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for statistical testing\n",
    "from scipy import stats\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# natural language processing\n",
    "import re\n",
    "import unicodedata\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# for natural language processing\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "# for modeling\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn import metrics\n",
    "\n",
    "# for time-series forecasting\n",
    "import matplotlib.pyplot as plt\n",
    "from prophet import Prophet\n",
    "\n",
    "# for working with timestamps\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "\n",
    "# for visualizations\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# to print out all the outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read a csv file\n",
    "df = pd.read_csv('../data/in/short_survey_data_with_asat_rr_csat.csv')\n",
    "\n",
    "# Read an excel file\n",
    "df = pd.read_excel('../data/in/short_survey_data_with_asat_rr_csat.xlsx')\n",
    "\n",
    "# Read a tsv file\n",
    "df = pd.read_csv('../data/in/short_survey_data_with_asat_rr_csat.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading All Files Within a Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Read filenames from the given path\n",
    "data_files = os.listdir('path/to/datafiles')\n",
    "\n",
    "def load_files(filenames):\n",
    "    for filename in filenames:\n",
    "        yield pd.read_csv(filename)\n",
    "\n",
    "data = pd.concat(load_files(data_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_missing(df):\n",
    "    \"\"\"\n",
    "    Takes a dataframe and returns a dataframe with stats\n",
    "    on missing and null values with their percentages.\n",
    "    \"\"\"\n",
    "    null_count = df.isnull().sum()\n",
    "    null_percentage = (null_count / df.shape[0]) * 100\n",
    "    empty_count = pd.Series(((df == ' ') | (df == '')).sum())\n",
    "    empty_percentage = (empty_count / df.shape[0]) * 100\n",
    "    nan_count = pd.Series(((df == 'nan') | (df == 'NaN')).sum())\n",
    "    nan_percentage = (nan_count / df.shape[0]) * 100\n",
    "    dfx = pd.DataFrame({'num_missing': null_count, 'missing_percentage': null_percentage,\n",
    "                         'num_empty': empty_count, 'empty_percentage': empty_percentage,\n",
    "                         'nan_count': nan_count, 'nan_percentage': nan_percentage})\n",
    "    return dfx\n",
    "\n",
    "show_missing(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show Value Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_values(df, columns):\n",
    "    \"\"\"\n",
    "    Take a dataframe and a list of columns and\n",
    "    returns the value counts for the columns.\n",
    "    \"\"\"\n",
    "    for column in columns:\n",
    "        print(column)\n",
    "        print('=====================================')\n",
    "        print(df[column].value_counts(dropna=False))\n",
    "        print('\\n')\n",
    "\n",
    "def show_values(df, param):\n",
    "    if param == 'all':\n",
    "        get_values(df, df.columns)\n",
    "    else:\n",
    "        get_values(df, param) \n",
    "\n",
    "show_values(df, ['asat'])\n",
    "show_values(df, 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenating DataFrames Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1,df2,df3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging Dataframe Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df1.merge(df2,\n",
    "                      left_on='id1',\n",
    "                      right_on='id2',\n",
    "                      suffixes=('_left', '_right'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using iLoc to Select Rows of a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single selections using iloc and DataFrame\n",
    "\n",
    "# Rows:\n",
    "df.iloc[0] # first row of data frame (Aleshia Tomkiewicz) - Note a Series data type output.\n",
    "df.iloc[1] # second row of data frame (Evan Zigomalas)\n",
    "df.iloc[-1] # last row of data frame (Mi Richan)\n",
    "\n",
    "# Columns:\n",
    "df.iloc[:,0] # first column of data frame (first_name)\n",
    "df.iloc[:,1] # second column of data frame (last_name)\n",
    "df.iloc[:,-1] # last column of data frame (id)\n",
    "\n",
    "# Multiple row and column selections using iloc and DataFrame\n",
    "\n",
    "df.iloc[0:5] # first five rows of dataframe\n",
    "df.iloc[:, 0:2] # first two columns of data frame with all rows\n",
    "df.iloc[[0,3,6,24], [0,5,6]] # 1st, 4th, 7th, 25th row + 1st 6th 7th columns.\n",
    "df.iloc[0:5, 5:8] # first 5 rows and 5th, 6th, 7th columns of data frame (county -> phone1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using loc to Select Rows of a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows with first name Ednalyn, include all columns between 'city' and 'email'\n",
    "df.loc[data['first_name'] == 'Ednalyn', 'city':'email']\n",
    " \n",
    "# Select rows where the email column ends with 'gmail.com', include all columns\n",
    "df.loc[data['email'].str.endswith(\"gmail.com\")]   \n",
    " \n",
    "# Select rows with first_name equal to some values, all columns\n",
    "df.loc[data['first_name'].isin(['Ednalyn', 'Ederlyne', 'Edelyn'])]   \n",
    "       \n",
    "# Select rows with first name Ednalyn and gmail email addresses\n",
    "df.loc[data['email'].str.endswith(\"gmail.com\") & (data['first_name'] == 'Ednalyn')] \n",
    " \n",
    "# select rows with id column between 100 and 200, and just return 'zip' and 'web' columns\n",
    "df.loc[(data['id'] > 100) & (df['id'] <= 200), ['zip', 'web']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Displaying the First and Last Rows of a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the Shape of a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Displaying the First Ten Items of a List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Displaying Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specifying Column Names in Bulk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns=['column_name', 'column_name', 'column_name', 'column_name', 'column_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handpicking Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = df[['column_name',\n",
    "          'column_name',\n",
    "          'column_name',\n",
    "          'column_name',\n",
    "          'column_name'\n",
    "        ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Renaming Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'old_name':'new_name',\n",
    "                        'old_name':'new_name',\n",
    "                        'old_name':'new_name',\n",
    "                        'old_name':'new_name',\n",
    "                        'old_name':'new_name'\n",
    "                        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset =\"column_id\", keep = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Unnamed: 0','Unnamed: 0.1','score'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting the Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('date_time_zone', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resetting the Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding DataFrame Column Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['col_total'] = df.col1 + df.col2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Column Based on a Conditional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'name': ['Jason', 'Molly', 'Tina', 'Jake', 'Amy'], \n",
    "        'age': [42, 52, 36, 24, 73], \n",
    "        'preTestScore': [4, 24, 31, 2, 3],\n",
    "        'postTestScore': [25, 94, 57, 62, 70]}\n",
    "df = pd.DataFrame(data, columns = ['name', 'age', 'preTestScore', 'postTestScore'])\n",
    "\n",
    "df['elderly'] = np.where(df['age']>=50, 'yes', 'no')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Column Based on Existing Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Date':['10/2/2011', '11/2/2011', '12/2/2011', '13/2/2011'], \n",
    "                    'Event':['Music', 'Poetry', 'Theatre', 'Comedy'], \n",
    "                    'Cost':[10000, 5000, 15000, 2000]})\n",
    "\n",
    "df['Discounted_Price'] = df.apply(lambda row: row.Cost - \n",
    "                                  (row.Cost * 0.1), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting Non-null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['column_name'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting Rows Where a Column is Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['col_name'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting Rows Where Column is in List of Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['col_name'].isin(list_of_values)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting Rows Where Column is Not in List of Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['col_name'].isin(list_of_values)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting Rows Based on Multiple Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['column_name'] >= A) & (df['column_name'] <= B)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Value Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.col_name.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Value Counts Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.concat([df.rating.value_counts(),\n",
    "                    df.rating.value_counts(normalize=True)], axis=1)\n",
    "labels.columns = ['n', 'percent']\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a List from Value Counts Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_index_values = df.col_name.value_counts(dropna=False).index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a DataFrame from Value Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.column_name.value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Info and Describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "df.describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "df[\"startDate\"] = pd.to_datetime(df[\"startDate\"])\n",
    "\n",
    "# extract time components from the timestamp column\n",
    "df2['year'] = df2.timestamp.dt.year\n",
    "df2['month'] = df2.timestamp.dt.month\n",
    "df2['day'] = df2.timestamp.dt.day\n",
    "df2['hour'] = df2.timestamp.dt.hour\n",
    "\n",
    "# extract time attributes from the timestamp column\n",
    "df2['day_of_year'] = df2.timestamp.dt.dayofyear\n",
    "df2['week_of_year'] = df2.timestamp.dt.weekofyear\n",
    "df2['day_of_week'] = df2.timestamp.dt.dayofweek\n",
    "\n",
    "# extract weekday characteristic from the day of the week column\n",
    "df2['weekday'] = np.where(df2['day_of_week'] < 5, True, False)\n",
    "\n",
    "# extract part of the day from the hour column\n",
    "def get_day_period(x):\n",
    "    if x in range(6,12):\n",
    "        return 'Morning'\n",
    "    elif x in range(12,18):\n",
    "        return 'Afternoon'\n",
    "    elif x in range(18,23):\n",
    "        return 'Evening'\n",
    "    else:\n",
    "        return 'Late night'\n",
    "\n",
    "df2['part_of_day'] = df2['hour'].apply(get_day_period)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designating CSAT vs DSAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a new column and designates a row as either high or low\n",
    "df['csat'] = np.where(df['rating']>=3, 'high', 'low')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting CSAT and DSAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive =  df.loc[df['column_name'] == 'positive']\n",
    "df_negative =  df.loc[df['column_name'] == 'negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_onehotencoded = pd.get_dummies(df, columns = ['column_name', 'column_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [10, 6]\n",
    "plt.rcParams[\"figure.autolayout\"] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the default Pearson for continuous variables\n",
    "corr_matrix = df_totals.corr(method ='pearson')\n",
    "\n",
    "# Use Spearman for ordinal variables\n",
    "corr_matrix = df_totals.corr(method ='spearman')\n",
    "\n",
    "# Setup\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "# vmin and vmax control the range of the colormap\n",
    "sns.heatmap(corr_matrix, cmap='RdBu', annot=True, fmt='.2f',\n",
    "           vmin=-1, vmax=1)\n",
    "\n",
    "plt.title(\"Correlations Between Something and Somethings\")\n",
    "\n",
    "# Add tight_layout to ensure the labels don't get cut off\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pairplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Violin Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "ax = sns.violinplot(x=\"category\", y=\"numeric\", data=df)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(x=\"category1\", y=\"numeric_measure\",\n",
    "                hue=\"binary_category\", col=\"category2\",\n",
    "                data=df, kind=\"violin\", split=True,\n",
    "                height=6, aspect=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Levene's Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.levene(df_group1['col_name'], df_group2['col_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Levene's Test Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levene_hom = []\n",
    "levene_het = []\n",
    "\n",
    "for column in columns_list:\n",
    "    \n",
    "    result = stats.levene(df_group1[column], df_group2[column])[1]\n",
    "    \n",
    "    if result > ALPHA:\n",
    "        interpretation = 'insignificant - HOMOGENOUS'\n",
    "        levene_hom.append(column)\n",
    "    else:\n",
    "        interpretation = 'significant - HETEROGENOUS'\n",
    "        levene_het.append(column)\n",
    "        \n",
    "    print(result, '-', column, ' - ', interpretation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shapiro Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = df_group1['col_name'] - df_group2['col_name']\n",
    "stats.shapiro(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mann-Whitney U Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA = 0.05\n",
    "\n",
    "stat, p = mannwhitneyu(df_group1[column], df_group2[column], df_group3[column])\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same distribution (fail to reject H0)')\n",
    "else:\n",
    "    print('Different distribution (reject H0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mann-Whitney U Test Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA = 0.05\n",
    "\n",
    "mannwhitneyu_same = []\n",
    "mannwhitneyu_diff = []\n",
    "\n",
    "for column in columns_list:\n",
    "    stat, p = mannwhitneyu(df_group1[column], df_group2[column], df_group3[column])\n",
    "    \n",
    "    if p > ALPHA:\n",
    "        interpretation = 'SAME (fail to reject H0)'\n",
    "        print('Statistics=%.3f, p=%.3f' % (stat, p) + ' - ' + column + ' - ' + interpretation)\n",
    "        mannwhitneyu_same.append(column)\n",
    "    else:\n",
    "        interpretation = 'DIFFERENT (reject H0)'\n",
    "        print('Statistics=%.3f, p=%.3f' % (stat, p) + ' - ' + column + ' - ' + interpretation)\n",
    "        mannwhitneyu_diff.append(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Independent T-testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(df_group1['col_name'], df_group2['col_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Independent T-testing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA = 0.05\n",
    "\n",
    "for column in levene_hom:\n",
    "    \n",
    "    result = stats.ttest_ind(df_group1[column], df_group2[column])[1]\n",
    "    \n",
    "    if result > ALPHA:\n",
    "        interpretation = 'insignificant - SAME'\n",
    "        ttest_same.append(column)\n",
    "    else:\n",
    "        interpretation = 'significant - DIFFERENT'\n",
    "        ttest_diff.append(column)\n",
    "        \n",
    "    print(result, '-', column, ' - ', interpretation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Treemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.treemap(df, path=['case_origin', 'case_tag'], values='score')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale continuous variables\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(df[['id_age']])\n",
    "\n",
    "df[['id_age']] = scaler.transform(df[['id_age']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_values(df4, ['high'])\n",
    "\n",
    "X = df4.loc[:, df4.columns != 'high']\n",
    "y = df4.loc[:, df4.columns == 'high']\n",
    "\n",
    "os = SMOTE(random_state=493)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=493)\n",
    "\n",
    "columns = X_train.columns\n",
    "os_data_X,os_data_y=os.fit_resample(X_train, y_train)\n",
    "os_data_X = pd.DataFrame(data=os_data_X,columns=columns )\n",
    "os_data_y= pd.DataFrame(data=os_data_y,columns=['high'])\n",
    "\n",
    "# we can check the numbers of our data\n",
    "print(\"length of oversampled data is \",len(os_data_X))\n",
    "print(\"Number of no subscription in oversampled data\",len(os_data_y[os_data_y['high']==0]))\n",
    "print(\"Number of subscription\",len(os_data_y[os_data_y['high']==1]))\n",
    "print(\"Proportion of no subscription data in oversampled data is \",len(os_data_y[os_data_y['high']==0])/len(os_data_X))\n",
    "print(\"Proportion of subscription data in oversampled data is \",len(os_data_y[os_data_y['high']==1])/len(os_data_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal Number of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of features\n",
    "features = [col for col in df]\n",
    "\n",
    "# create list of lists that increase number of features in list\n",
    "that_list = []\n",
    "list_of_feature_lists = []\n",
    "for i in range(1,len(features)):\n",
    "    that_list = features[0:i]\n",
    "    list_of_feature_lists.append(that_list)\n",
    "    \n",
    "# loop to identify efficacy of models\n",
    "for list_item in list_of_feature_lists:\n",
    "    xgb_cl = xgb.XGBClassifier()\n",
    "    xgb_cl.fit(os_data_X[list_item], os_data_y)\n",
    "    preds = xgb_cl.predict(X_test[list_item])\n",
    "\n",
    "    print(\"Accuracy Score: \" + str(accuracy_score(y_test, preds)))\n",
    "    print(\"Number of features: \" + str(len(list_item)))\n",
    "    print('--------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=493)\n",
    "\n",
    "logreg = LogisticRegression(solver=\"saga\")\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))\n",
    "\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(confusion_matrix)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-Series Forecasting with Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.read_csv('blood_glucose.csv', parse_dates=True, infer_datetime_format=True)\n",
    "df5 = df5.rename(columns={'startDate':'ds', 'value':'y'})\n",
    "df5[\"ds\"] = pd.to_datetime(df5[\"ds\"])\n",
    "df5['ds'] = df5['ds'].dt.tz_localize(None)\n",
    "df6=df5.set_index('ds').resample('D').agg(y=('y', 'mean'))\n",
    "df6 = df6.reset_index()\n",
    "\n",
    "model = Prophet()\n",
    "model.fit(df6)\n",
    "df6_forecast = model.make_future_dataframe(periods=12, freq='MS')\n",
    "df6_forecast = model.predict(df6_forecast)\n",
    "plt.figure(figsize=(18, 6))\n",
    "model.plot(df6_forecast, xlabel = 'Timestamp', ylabel = 'Glucose')\n",
    "plt.title('Blood Glucose')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XML to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create element tree object\n",
    "tree = ET.parse('export.xml')\n",
    "\n",
    "# extract the attributes for every health record\n",
    "root = tree.getroot()\n",
    "record_list = [x.attrib for x in root.iter('Record')]\n",
    "\n",
    "# create the dataframe\n",
    "df = pd.DataFrame(record_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADDITIONAL_STOPWORDS = ['ignore', 'me']\n",
    "\n",
    "def clean(sentence):\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    stopwords = nltk.corpus.stopwords.words('english') + ADDITIONAL_STOPWORDS\n",
    "    sentence = (unicodedata.normalize('NFKD', sentence)\n",
    "        .encode('ascii', 'ignore')\n",
    "        .decode('utf-8', 'ignore')\n",
    "        .lower())\n",
    "    words = re.sub(r'[^\\w\\s]', '', sentence).split()\n",
    "    word_list = [wnl.lemmatize(word) for word in words if word not in stopwords]\n",
    "    return word_list\n",
    "\n",
    "clean('The quick brown fox jumps over the lazy dog. Ignore me.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_words(df, column):\n",
    "    \"\"\"\n",
    "    Takes a dataframe and a column and returns a list of\n",
    "    cleaned words that is returned by clean().\n",
    "\n",
    "            Parameters:\n",
    "                    df (dataframe): A pandas dataframe\n",
    "                    column (series): A pandas series\n",
    "\n",
    "            Returns:\n",
    "                    word_list (list): A list of cleaned words\n",
    "    \"\"\"\n",
    "    return clean(''.join(str(df[column].tolist())))\n",
    "\n",
    "get_words(df, 'comment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unique Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csat =  df.loc[df['score'] == 1]\n",
    "df_dsat =  df.loc[df['score'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csat_words = get_words(df_csat, 'comment')\n",
    "dsat_words = get_words(df_dsat, 'comment')\n",
    "all_words = get_words(df, 'comment')\n",
    "\n",
    "csat_freq = pd.Series(csat_words).value_counts()\n",
    "dsat_freq = pd.Series(dsat_words).value_counts()\n",
    "all_freq = pd.Series(all_words).value_counts()\n",
    "\n",
    "word_counts = (pd.concat([all_freq, csat_freq, dsat_freq], axis=1, sort=True)\n",
    "                .set_axis(['all', 'csat', 'dsat'], axis=1, inplace=False)\n",
    "                .fillna(0)\n",
    "                .apply(lambda s: s.astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the most frequently occuring words?\n",
    "word_counts.sort_values(by='all', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there any words that uniquely identify a dsat or csat comment?\n",
    "pd.concat([word_counts[word_counts.dsat == 0].sort_values(by='csat').tail(10),\n",
    "           word_counts[word_counts.csat == 0].sort_values(by='dsat').tail(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unigrams(words):\n",
    "    \"\"\"\n",
    "    Takes in a list of words and returns a series of\n",
    "    unigrams with value counts.\n",
    "    \"\"\"\n",
    "    return  pd.Series(words).value_counts()\n",
    "\n",
    "def get_bigrams(words):\n",
    "    \"\"\"\n",
    "    Takes in a list of words and returns a series of\n",
    "    bigrams with value counts.\n",
    "    \"\"\"\n",
    "    return (pd.Series(nltk.ngrams(words, 2)).value_counts())[:20]\n",
    "\n",
    "def get_trigrams(words):\n",
    "    \"\"\"\n",
    "    Takes in a list of words and returns a series of\n",
    "    trigrams with value counts.\n",
    "    \"\"\"\n",
    "    return (pd.Series(nltk.ngrams(words, 3)).value_counts())[:20]\n",
    "\n",
    "def get_qualgrams(words):\n",
    "    \"\"\"\n",
    "    Takes in a list of words and returns a series of\n",
    "    qualgrams with value counts.\n",
    "    \"\"\"\n",
    "    return (pd.Series(nltk.ngrams(words, 4)).value_counts())[:20]\n",
    "\n",
    "def get_ngrams(df,column):\n",
    "    \"\"\"\n",
    "    Takes in a dataframe with column name and generates a\n",
    "    dataframe of unigrams, bigrams, trigrams, and qualgrams.\n",
    "    \"\"\"\n",
    "    return get_bigrams(get_words(df,column)).to_frame().reset_index().rename(columns={'index':'bigram','0':'count'}), \\\n",
    "           get_trigrams(get_words(df,column)).to_frame().reset_index().rename(columns={'index':'trigram','0':'count'}), \\\n",
    "           get_qualgrams(get_words(df,column)).to_frame().reset_index().rename(columns={'index':'qualgram','0':'count'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize N-grams with Bar Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_bigrams(df, column, title):\n",
    "    \"\"\"\n",
    "    Takes in a dataframe, target column name, and specified title\n",
    "    for the bar chart visualization of bigrams.\n",
    "    \"\"\"\n",
    "    get_bigrams(get_words(df,column)).sort_values().plot.barh(color='blue', width=.9, figsize=(12, 8))\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Bigram')\n",
    "    plt.xlabel('# Occurances')\n",
    "\n",
    "def viz_trigrams(df, column, title):\n",
    "    \"\"\"\n",
    "    Takes in a dataframe, target column name, and specified title\n",
    "    for the bar chart visualization of trigrams.\n",
    "    \"\"\"\n",
    "    get_trigrams(get_words(df,column)).sort_values().plot.barh(color='blue', width=.9, figsize=(12, 8))\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Trigram')\n",
    "    plt.xlabel('# Occurances')\n",
    "    \n",
    "def viz_qualgrams(df, column, title):\n",
    "    \"\"\"\n",
    "    Takes in a dataframe, target column name, and specified title\n",
    "    for the bar chart visualization of qualgrams.\n",
    "    \"\"\"\n",
    "    get_bigrams(get_words(df,column)).sort_values().plot.barh(color='blue', width=.9, figsize=(12, 8))\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Qualgram')\n",
    "    plt.xlabel('# Occurances')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping with Selenium and Beautiful Soup 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_PAGES = 2\n",
    "assert NUM_PAGES > 1, \"NUM_PAGES should be more than 1.\"\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "links = []\n",
    "\n",
    "# opens Chrome window\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# get the links on the first page\n",
    "driver.get(\"https://www.sa.gov/Directory/Departments/CE/Media-Relations/News-Releases\")\n",
    "post_links = driver.find_elements(By.CSS_SELECTOR, 'article a')\n",
    "for link in post_links:\n",
    "    links.append(link.get_attribute(\"href\"))\n",
    "\n",
    "# get the links on subsequent pages\n",
    "for page_num in range(2, NUM_PAGES + 1):\n",
    "    driver.get(\"https://www.sa.gov/Directory/Departments/CE/Media-Relations/News-Releases?dlv_OCP%20CL%20Main%20Press%20Release%20Listing=(pageindex=\" + str(page_num) + \")\")\n",
    "    post_links = driver.find_elements(By.CSS_SELECTOR, 'article a')\n",
    "    for link in post_links:\n",
    "        links.append(link.get_attribute(\"href\"))\n",
    "\n",
    "# closes Chrome window\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_list_to_file(lst, filename):\n",
    "    \"\"\"\n",
    "    Takes a list of links and turns each one to a file.\n",
    "    \"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        for item in lst:\n",
    "            f.write(str(item) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def current_time_to_serial():\n",
    "    \"\"\"\n",
    "    Returns the current timestamp in serial format.\n",
    "    \"\"\"\n",
    "    current_time = datetime.now()\n",
    "    return current_time.timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for post_link in links:\n",
    "    soup = BeautifulSoup(requests.get(post_link).content, 'html.parser')\n",
    "    \n",
    "    # Find all elements with the specified class\n",
    "    contents = soup.find_all('div', class_='grid')\n",
    "\n",
    "    texts = []\n",
    "    \n",
    "    # Iterate through the div elements\n",
    "    for content in contents:\n",
    "        # Find and extract text from paragraphs\n",
    "        paragraphs = content.find_all('p')\n",
    "        paragraph_texts = [p.get_text() for p in paragraphs]\n",
    "        texts.append(paragraph_texts)\n",
    "\n",
    "    save_list_to_file(texts, \"../data/content-\" + str(current_time_to_serial()) + \".txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a corpus from text files in a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# LIMIT\n",
    "LIMIT = 4999\n",
    "\n",
    "FOLDER_PATH  = \"C:/Users/Dd/OneDrive/Documents/_github/knowledge-graph-rag/data\"\n",
    "\n",
    "os.chdir(FOLDER_PATH)\n",
    "documents = []\n",
    "  \n",
    "# iterate through all files\n",
    "for file in os.listdir(): \n",
    "    # Check whether file is in text format or not \n",
    "    if file.endswith(\".txt\"):\n",
    "        size = os.path.getsize(os.path.join(file))\n",
    "        if size < LIMIT:\n",
    "            file_path = f\"{FOLDER_PATH}/{file}\"\n",
    "            with open(file_path, 'r', encoding = \"cp1252\") as f:\n",
    "                documents.append(f.read())\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting relationships from corpus in JSON format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an expert on  knowledge graph specializing on extracting entities and relationships.\n",
    "\n",
    "Your task is to identify the entities and relations requested with the user prompt, from a given document.\n",
    "\n",
    "You must generate the output in a JSON containing a list with JSON objects having first level keys only: \"head\", \"head_type\",\n",
    "\"relation\", \"tail\", and \"tail_type\".\n",
    "\n",
    "The \"head\" key must contain the text of the extracted entity,\n",
    "the \"head_type\" key must contain the type of the extracted head entity,\n",
    "the \"relation\" key must contain the type of relation between the \"head\" and the \"tail\", the \"tail\" key must represent the text of an\n",
    "extracted entity which is the tail of the relation, and the \"tail_type\" key must contain the type of the tail entity.\n",
    "\n",
    "Attempt to extract as many entities and relations as you can but do not make things up.\n",
    "\n",
    "The JSON must have only \"head\", \"head_type\", \"relation\", \"tail\", and \"tail_type\" as first-level keys.\n",
    "Do not use any other keys.\n",
    "Do not use entities or extracted entities as keys.\n",
    "\n",
    "Use the following format as an example output:\n",
    "\n",
    "[\n",
    "\n",
    "  {{\n",
    "    \"head\": \"President Biden\",\n",
    "    \"head_type\": \"organization\",\n",
    "    \"relation\": \"working for\",\n",
    "    \"tail\": \"American people\",\n",
    "    \"tail_type\": \"organization\"\n",
    "  }}\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"Based on the following example, extract entities and relations from the provided document.\n",
    "\n",
    "--> Beginning of example\n",
    "\n",
    "# Document\n",
    "\"We'll be in touch with the latest information on how President Biden and his administration\n",
    "are working for the American people. Today, Israeli security forces conducted a successful\n",
    "operation to rescue four hostages from the grips of Hamas in Gaza.\"\n",
    "\n",
    "################\n",
    "\n",
    "# Output\n",
    "[\n",
    "\n",
    "  {{\n",
    "    \"head\": \"President Biden\",\n",
    "    \"head_type\": \"organization\",\n",
    "    \"relation\": \"working for\",\n",
    "    \"tail\": \"American people\",\n",
    "    \"tail_type\": \"organization\"\n",
    "  }}\n",
    "]\n",
    "\n",
    "--> End of example\n",
    "\n",
    "For the following document, generate extract entities and relations as in the provided example.\n",
    "\n",
    "# Document\n",
    "{document}\n",
    "\n",
    "\n",
    "################\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_information(text, model=\"gpt-3.5-turbo\"):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_prompt.format(\n",
    "                    document=document\n",
    "                )\n",
    "            }\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    \n",
    "    print(completion.choices[0].message.content)\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg = []\n",
    "for document in documents:\n",
    "    clean_document = document.encode() \\\n",
    "                .decode('unicode-escape') \\\n",
    "                .replace('\\xa0',' ') \\\n",
    "                .replace('\\t',' ') \\\n",
    "                .replace('â€™', '')\n",
    "    extracted_relationships = extract_information(clean_document)\n",
    "    clean_relationships = json.loads(extracted_relationships)\n",
    "    kg.append(clean_relationships)\n",
    "kg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Knowledge Graph from JSON using NetworkX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relationships = pd.DataFrame(kg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "for _, row in relationships.iterrows():\n",
    "  G.add_edge(row['head'], row['tail'], label=row['relation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.spring_layout(G, seed=47, k=0.9)\n",
    "labels = nx.get_edge_attributes(G, 'label')\n",
    "plt.figure(figsize=(15, 15))\n",
    "nx.draw(G, pos, with_labels=True, font_size=10, node_size=700, node_color='lightblue', edge_color='gray', alpha=0.6)\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=labels, font_size=8, label_pos=0.3, verticalalignment='baseline')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relationships.to_csv('../data/relations.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connecting to Neo4j and importing a dataframe of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.graphs import Neo4jGraph\n",
    "\n",
    "url = \"bolt://localhost:7687\"\n",
    "username =\"neo4j\"\n",
    "password = db_password\n",
    "\n",
    "graph = Neo4jGraph(\n",
    "    url=url, \n",
    "    username=username, \n",
    "    password=password\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_query = \"\"\"\n",
    "LOAD CSV FROM 'file:///relations.csv' AS row\n",
    "MERGE (e:Person {head: row[1], tail: row[3], relation: row[2]})\n",
    "RETURN e.head, e.tail, e.relation\n",
    "\"\"\"\n",
    "graph.query(\n",
    "    import_query\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the vector store for RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores.neo4j_vector import Neo4jVector\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "vector_index = Neo4jVector.from_existing_graph(\n",
    "    OpenAIEmbeddings(openai_api_key=api_key),\n",
    "    url=url,\n",
    "    username=username,\n",
    "    password=password,\n",
    "    index_name='person',\n",
    "    node_label=\"Person\",\n",
    "    text_node_properties=['head', 'tail', 'relation'],\n",
    "    embedding_node_property='embedding',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying with RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "vector_qa = RetrievalQA.from_chain_type(\n",
    "    llm=ChatOpenAI(openai_api_key=OPENAI_API_KEY), chain_type=\"stuff\", retriever=vector_index.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_qa.invoke(\n",
    "    {\"query\": \"How many pools did the San Antonio Parks and Recreation open?\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vector_qa.invoke(\n",
    "    {\"query\": \"What did the San Antonio Parks and Recreation announce?\"}\n",
    ")\n",
    "\n",
    "print(result['result'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
